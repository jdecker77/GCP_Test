{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import visualize\n",
    "from model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco_humanpose.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Directory of images to run detection on\n",
    "COCO_DIR = \"/home/xiaowu/Documents/Mask_RCNN_Humanpose-master/images\"  # TODO: enter you own value here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jessedecker/miniconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/jessedecker/projects/rail_segmentation/resources/Keypoints-of-humanpose-with-Mask-R-CNN-master/model.py:673: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jessedecker/projects/rail_segmentation/resources/Keypoints-of-humanpose-with-Mask-R-CNN-master/utils.py:251: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jessedecker/projects/rail_segmentation/resources/Keypoints-of-humanpose-with-Mask-R-CNN-master/model.py:717: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "WARNING:tensorflow:From /Users/jessedecker/projects/rail_segmentation/resources/Keypoints-of-humanpose-with-Mask-R-CNN-master/model.py:1300: The name tf.image.resize_bilinear is deprecated. Please use tf.compat.v1.image.resize_bilinear instead.\n",
      "\n",
      "Loading weights from  /Users/jessedecker/projects/rail_segmentation/resources/Keypoints-of-humanpose-with-Mask-R-CNN-master/mask_rcnn_coco_humanpose.h5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.engine.topology' has no attribute 'load_weights_from_hdf5_group_by_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e6f572929d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m model.load_weights(model_path, by_name=True,exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n\u001b[0;32m---> 22\u001b[0;31m                                 \"mrcnn_bbox\", \"mrcnn_mask\"])\n\u001b[0m",
      "\u001b[0;32m~/projects/rail_segmentation/resources/Keypoints-of-humanpose-with-Mask-R-CNN-master/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2842\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.engine.topology' has no attribute 'load_weights_from_hdf5_group_by_name'"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    USE_MINI_MASK = True\n",
    "    IMAGE_MIN_DIM = 256\n",
    "    IMAGE_MAX_DIM = 256\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", \n",
    "                          config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "model_path = COCO_MODEL_PATH\n",
    "# Load trained weights (fill in path to trained weights here)\n",
    "assert model_path != \"\", \"Provide path to trained weights\"\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True,exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "assert config.NAME == \"coco\"\n",
    "# Training dataset\n",
    "#load person keypoints dataset\n",
    "train_dataset_keypoints = coco.CocoDataset(task_type=\"person_keypoints\")\n",
    "train_dataset_keypoints.load_coco(COCO_DIR, \"train\")\n",
    "train_dataset_keypoints.prepare() \n",
    "print(\"Train Keypoints Image Count: {}\".format(len(train_dataset_keypoints.image_ids)))\n",
    "print(\"Train Keypoints Class Count: {}\".format(train_dataset_keypoints.num_classes))\n",
    "for i, info in enumerate(train_dataset_keypoints.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "\n",
    "image_id = random.choice(train_dataset_keypoints.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask, gt_keypoint =\\\n",
    "    modellib.load_image_gt_keypoints(train_dataset_keypoints, config, \n",
    "                           image_id, augment=False,use_mini_mask=config.USE_MINI_MASK)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "log(\"gt_keypoint\", gt_keypoint)\n",
    "\n",
    "visualize.display_keypoints(original_image,gt_bbox,gt_keypoint,gt_class_id,train_dataset_keypoints.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Inspect the flipping augument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(train_dataset_keypoints.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask, gt_keypoint =\\\n",
    "    modellib.load_image_gt_keypoints(train_dataset_keypoints, config, \n",
    "                           image_id, augment=False,use_mini_mask=config.USE_MINI_MASK)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "log(\"gt_keypoint\", gt_keypoint)\n",
    "\n",
    "visualize.display_keypoints(original_image,gt_bbox,gt_keypoint,gt_class_id,train_dataset_keypoints.class_names)\n",
    "if(config.USE_MINI_MASK):\n",
    "    gt_mask = utils.expand_mask(gt_bbox,gt_mask,original_image.shape)\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            train_dataset_keypoints.class_names,)\n",
    "\n",
    "original_image_flip, image_meta_flip, gt_class_id_flip, gt_bbox_flip, gt_mask_flip, gt_keypoint_flip =\\\n",
    "    modellib.load_image_gt_keypoints(train_dataset_keypoints, config, \n",
    "                           image_id, augment=True,use_mini_mask=config.USE_MINI_MASK)\n",
    "\n",
    "\n",
    "visualize.display_keypoints(original_image_flip,gt_bbox_flip,gt_keypoint_flip,gt_class_id_flip,train_dataset_keypoints.class_names)\n",
    "if(config.USE_MINI_MASK):\n",
    "    gt_mask_flip = utils.expand_mask(gt_bbox_flip,gt_mask_flip,original_image_flip.shape)\n",
    "visualize.display_instances(original_image_flip, gt_bbox_flip, gt_mask_flip, gt_class_id_flip, \n",
    "                            train_dataset_keypoints.class_names,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Inspect the DetectionKeypointTargetLayer\n",
    "This layers generated the ground truth keypoint labels and their values are between[0, 56*56).\n",
    "Here we run a sub graph to generated the ground truth target and visulize them to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rois, target_class_ids, target_bbox, target_keypoint, target_keypoint_weight, target_mask\n",
    "train_keypoint_generator = modellib.data_generator_keypoint(train_dataset_keypoints, config, shuffle=True,\n",
    "                                         batch_size=config.BATCH_SIZE)\n",
    "\n",
    "#python 3.* use nexy(generator)\n",
    "inputs,_ = next(train_keypoint_generator)\n",
    "batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox, batch_gt_class_ids, \\\n",
    "            batch_gt_boxes, batch_gt_keypoints,batch_gt_masks  = inputs\n",
    "log(\"batch_images\",batch_images)\n",
    "log(\"batch_image_meta\",batch_image_meta)\n",
    "log(\"batch_rpn_match\",batch_rpn_match)\n",
    "log(\"batch_rpn_bbox\",batch_rpn_bbox)\n",
    "log(\"batch_gt_class_ids\",batch_gt_class_ids)\n",
    "log(\"batch_gt_boxes\",batch_gt_boxes)\n",
    "log(\"batch_gt_keypoints\",batch_gt_keypoints)\n",
    "log(\"batch_gt_masks\",batch_gt_masks)\n",
    "\n",
    "rpn = model.run_graph(inputs, [\n",
    "    (\"rois\", model.keras_model.get_layer(\"proposal_targets\").output[0]),\n",
    "    (\"target_class_ids\", model.keras_model.get_layer(\"proposal_targets\").output[1]),\n",
    "    (\"target_bbox\", model.keras_model.get_layer(\"proposal_targets\").output[2]),\n",
    "    (\"target_keypoint_lables\", model.keras_model.get_layer(\"proposal_targets\").output[3]),\n",
    "    (\"target_keypoint_weights\", model.keras_model.get_layer(\"proposal_targets\").output[4]),\n",
    "    (\"target_mask\", model.keras_model.get_layer(\"proposal_targets\").output[5]),\n",
    "])\n",
    "\n",
    "roi = rpn[\"rois\"]\n",
    "target_class_ids = rpn[\"target_class_ids\"]\n",
    "target_bbox = rpn[\"target_bbox\"]\n",
    "target_keypoint_label = rpn[\"target_keypoint_lables\"]\n",
    "target_keypoint_weight = rpn[\"target_keypoint_weights\"]\n",
    "target_mask = rpn[\"target_mask\"]\n",
    "# gt_keypoints = rpn[\"gt_keypoints\"]\n",
    "keypoint_scales = [config.IMAGE_SHAPE[1],config.IMAGE_SHAPE[0],1]\n",
    "# gt_keypoints = keypoint_scales*gt_keypoints\n",
    "log(\"real\")\n",
    "for i in range(config.BATCH_SIZE):\n",
    "    batch_orignal_image = modellib.unmold_image(batch_images[i],config)\n",
    "    visualize.display_image_keypoint_mask(batch_orignal_image,roi[i],target_keypoint_label[i],target_keypoint_weight[i],\n",
    "                                          target_class_ids[i],train_dataset_keypoints.class_names,config=config,iskeypointlabel= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Inspect some layers in build_fpn_keypoint_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn = model.run_graph(inputs, [\n",
    "    (\"mrcnn_keypoint_mask_upsample_1\", model.keras_model.get_layer(\"mrcnn_keypoint_mask_upsample_1\").output),\n",
    "    (\"mrcnn_keypoint_mask_transpose\", model.keras_model.get_layer(\"mrcnn_keypoint_mask_transpose\").output),\n",
    "    (\"mrcnn_keypoint_mask_reshape\", model.keras_model.get_layer(\"mrcnn_keypoint_mask_reshape\").output),\n",
    "])\n",
    "plot.imshow(rpn[\"mrcnn_keypoint_mask_reshape\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Inspect the inner value of keypoint_mrcnn_mask_loss_graph\n",
    "    Before you run this cell, you must uncomment the \"test_mrcnn_mask_loss_graph\" in the model.py(Line 2726-2727) and add it in the output list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn = model.run_graph(inputs, [\n",
    "    (\"pred_keypoint\", model.keras_model.get_layer(\"pred_keypoint\").output),\n",
    "    (\"target_keypoint\", model.keras_model.get_layer(\"target_keypoint\").output),\n",
    "    (\"target_class_ids_reshape\", model.keras_model.get_layer(\"target_class_ids_reshape\").output),\n",
    "    \n",
    "    (\"pred_keypoint_reshape\", model.keras_model.get_layer(\"pred_keypoint_reshape\").output),\n",
    "    (\"target_keypoint_reshape\", model.keras_model.get_layer(\"target_keypoint_reshape\").output),\n",
    "    (\"positive_pred_keypoint_masks\", model.keras_model.get_layer(\"positive_pred_keypoint_masks\").output),\n",
    "    (\"positive_target_keypoints\", model.keras_model.get_layer(\"positive_target_keypoints\").output),\n",
    "    (\"soft_loss\", model.keras_model.get_layer(\"soft_loss\").output),\n",
    "    (\"positive_loss\", model.keras_model.get_layer(\"positive_loss\").output),\n",
    "    (\"num_valid\", model.keras_model.get_layer(\"num_valid\").output),\n",
    "    (\"keypoint_loss\", model.keras_model.get_layer(\"keypoint_loss\").output),\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

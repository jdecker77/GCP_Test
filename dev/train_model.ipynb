{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Pantograph Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've been imported\n",
      "Using Root dir: /home/jupyter/GCP_Test\n",
      "Using Model dir: /home/jupyter/GCP_Test/models\n",
      "Using Data dir: /home/jupyter/GCP_Test/datasets/pantograph\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "# Add root to path \n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)\n",
    "\n",
    "# Import Mask RCNN\n",
    "# from mrcnn.config import Config\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "# Import pantogrograph class\n",
    "from dev import pantograph\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"models\")\n",
    "\n",
    "# Set path to root of images. \n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"datasets/pantograph\")\n",
    "\n",
    "\n",
    "print(\"Using Root dir:\",ROOT_DIR)\n",
    "print(\"Using Model dir:\",MODEL_DIR)\n",
    "print(\"Using Data dir:\",DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations Superlee:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_SHAPES                [[256 256]\n",
      " [128 128]\n",
      " [ 64  64]\n",
      " [ 32  32]\n",
      " [ 16  16]]\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        50\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "GPU_COUNT                      1\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                0.5\n",
      "IMAGE_PADDING                  True\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "KEYPOINT_MASK_POOL_SIZE        7\n",
      "KEYPOINT_MASK_SHAPE            [56, 56]\n",
      "KEYPOINT_THRESHOLD             0.005\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               128\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (224, 224)\n",
      "NAME                           pantograph\n",
      "NUM_CLASSES                    4\n",
      "NUM_KEYPOINTS                  6\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              2\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                150\n",
      "TRAIN_ROIS_PER_IMAGE           256\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               15\n",
      "WEIGHT_DECAY                   0.0001\n",
      "WEIGHT_LOSS                    True\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load class config and overwrite values as needed\n",
    "class InferenceConfig(pantograph.PantographConfig):\n",
    "    pass\n",
    "#     MASK_POOL_SIZE = 14\n",
    "#     KEYPOINT_MASK_POOL_SIZE = 7\n",
    "#     POOL_SIZE =\n",
    "#     BACKBONE = \"resnet50\"\n",
    "#     STEPS_PER_EPOCH = 150\n",
    "#     RPN_TRAIN_ANCHORS_PER_IMAGE = 200\n",
    "#     TRAIN_ROIS_PER_IMAGE = 200\n",
    "#     STEPS_PER_EPOCH = 2000\n",
    "#     LEARNING_RATE = .02\n",
    "#     USE_MINI_MASK = False\n",
    "#     RPN_ANCHOR_SCALES = (64, 128, 256, 512,1024)\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.63s)\n",
      "creating index...\n",
      "index created!\n",
      "Skeleton: (5, 2)\n",
      "Keypoint names: (6,)\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "Skeleton: (5, 2)\n",
      "Keypoint names: (6,)\n",
      "Train Keypoints Image Count: 300\n",
      "Train Keypoints Class Count: 4\n",
      "  0. BG                                                \n",
      "  1. front_bar                                         \n",
      "  2. middle_bar                                        \n",
      "  3. rear_bar                                          \n",
      "Val Keypoints Image Count: 30\n",
      "Val Keypoints Class Count: 4\n",
      "  0. BG                                                \n",
      "  1. front_bar                                         \n",
      "  2. middle_bar                                        \n",
      "  3. rear_bar                                          \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "assert config.NAME == \"pantograph\"\n",
    "\n",
    "# Training dataset\n",
    "train_dataset_keypoints = pantograph.PantographDataset()\n",
    "train_dataset_keypoints.load_pantograph(DATA_DIR, \"train\")\n",
    "train_dataset_keypoints.prepare()\n",
    "\n",
    "#Validation dataset\n",
    "val_dataset_keypoints = pantograph.PantographDataset()\n",
    "val_dataset_keypoints.load_pantograph(DATA_DIR, \"val\")\n",
    "val_dataset_keypoints.prepare()\n",
    "\n",
    "print(\"Train Keypoints Image Count: {}\".format(len(train_dataset_keypoints.image_ids)))\n",
    "print(\"Train Keypoints Class Count: {}\".format(train_dataset_keypoints.num_classes))\n",
    "for i, info in enumerate(train_dataset_keypoints.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
    "\n",
    "print(\"Val Keypoints Image Count: {}\".format(len(val_dataset_keypoints.image_ids)))\n",
    "print(\"Val Keypoints Class Count: {}\".format(val_dataset_keypoints.num_classes))\n",
    "for i, info in enumerate(val_dataset_keypoints.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/jupyter/GCP_Test/mrcnn/model.py:728: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    }
   ],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", \n",
    "                          config=config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "\n",
    "\n",
    "# Which weights to start with?\n",
    "init_with = \"last\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that are different due to the different number of classes    \n",
    "    MODEL_PATH = os.path.join(MODEL_DIR, \"mask_rcnn_coco.h5\")\n",
    "    model.load_weights(MODEL_PATH, by_name=True,exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == 'last':\n",
    "    LOG_DIR = os.path.join(MODEL_DIR, \"pantograph20200429T1039\")\n",
    "    MODEL_PATH = os.path.join(LOG_DIR, \"mask_rcnn_pantograph_0410.h5\")\n",
    "    model.load_weights(MODEL_PATH, by_name=True,exclude=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.keras_model.summary()\n",
    "# model.get_trainable_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 411. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_keypoint_mask_conv1   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn1   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv2   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn2   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv3   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn3   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv4   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn4   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv5   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn5   (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv6   (TimeDistributed)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn6   (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv7   (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn7   (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_keypoint_mask_conv8   (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_keypoint_mask_bn8   (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_keypoint_mask_deconv   (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/1000\n",
      "150/150 [==============================] - 88s 586ms/step - loss: 2.5265 - val_loss: 2.9954\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "\n",
      "Epoch 00412: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0412.h5\n",
      "Epoch 413/1000\n",
      "150/150 [==============================] - 68s 453ms/step - loss: 2.5208 - val_loss: 2.9804\n",
      "\n",
      "Epoch 00413: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0413.h5\n",
      "Epoch 414/1000\n",
      "150/150 [==============================] - 69s 457ms/step - loss: 2.5229 - val_loss: 2.9618\n",
      "\n",
      "Epoch 00414: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0414.h5\n",
      "Epoch 415/1000\n",
      "150/150 [==============================] - 75s 500ms/step - loss: 2.5264 - val_loss: 2.9961\n",
      "\n",
      "Epoch 00415: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0415.h5\n",
      "Epoch 416/1000\n",
      "150/150 [==============================] - 70s 468ms/step - loss: 2.5278 - val_loss: 3.1979\n",
      "\n",
      "Epoch 00416: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0416.h5\n",
      "Epoch 417/1000\n",
      "150/150 [==============================] - 71s 473ms/step - loss: 2.5064 - val_loss: 3.0530\n",
      "\n",
      "Epoch 00417: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0417.h5\n",
      "Epoch 418/1000\n",
      "150/150 [==============================] - 69s 463ms/step - loss: 2.5177 - val_loss: 3.2923\n",
      "\n",
      "Epoch 00418: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0418.h5\n",
      "Epoch 419/1000\n",
      "150/150 [==============================] - 67s 449ms/step - loss: 2.5330 - val_loss: 3.0150\n",
      "\n",
      "Epoch 00419: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0419.h5\n",
      "Epoch 420/1000\n",
      "150/150 [==============================] - 77s 512ms/step - loss: 2.5112 - val_loss: 3.1910\n",
      "\n",
      "Epoch 00420: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0420.h5\n",
      "Epoch 421/1000\n",
      "150/150 [==============================] - 78s 522ms/step - loss: 2.5124 - val_loss: 3.3739\n",
      "\n",
      "Epoch 00421: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0421.h5\n",
      "Epoch 422/1000\n",
      "150/150 [==============================] - 77s 514ms/step - loss: 2.5180 - val_loss: 3.1672\n",
      "\n",
      "Epoch 00422: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0422.h5\n",
      "Epoch 423/1000\n",
      "150/150 [==============================] - 68s 450ms/step - loss: 2.5062 - val_loss: 3.1107\n",
      "\n",
      "Epoch 00423: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0423.h5\n",
      "Epoch 424/1000\n",
      "150/150 [==============================] - 69s 461ms/step - loss: 2.5135 - val_loss: 3.2156\n",
      "\n",
      "Epoch 00424: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0424.h5\n",
      "Epoch 425/1000\n",
      "150/150 [==============================] - 68s 455ms/step - loss: 2.5038 - val_loss: 3.1083\n",
      "\n",
      "Epoch 00425: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0425.h5\n",
      "Epoch 426/1000\n",
      "150/150 [==============================] - 76s 504ms/step - loss: 2.5104 - val_loss: 3.1605\n",
      "\n",
      "Epoch 00426: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0426.h5\n",
      "Epoch 427/1000\n",
      "150/150 [==============================] - 78s 523ms/step - loss: 2.5300 - val_loss: 3.0592\n",
      "\n",
      "Epoch 00427: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0427.h5\n",
      "Epoch 428/1000\n",
      "150/150 [==============================] - 78s 519ms/step - loss: 2.5255 - val_loss: 3.1533\n",
      "\n",
      "Epoch 00428: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0428.h5\n",
      "Epoch 429/1000\n",
      "150/150 [==============================] - 71s 474ms/step - loss: 2.5103 - val_loss: 3.4447\n",
      "\n",
      "Epoch 00429: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0429.h5\n",
      "Epoch 430/1000\n",
      "150/150 [==============================] - 78s 517ms/step - loss: 2.4998 - val_loss: 3.3177\n",
      "\n",
      "Epoch 00430: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0430.h5\n",
      "Epoch 431/1000\n",
      "150/150 [==============================] - 68s 453ms/step - loss: 2.4860 - val_loss: 3.2281\n",
      "\n",
      "Epoch 00431: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0431.h5\n",
      "Epoch 432/1000\n",
      "150/150 [==============================] - 78s 517ms/step - loss: 2.4957 - val_loss: 3.0925\n",
      "\n",
      "Epoch 00432: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0432.h5\n",
      "Epoch 433/1000\n",
      "150/150 [==============================] - 68s 456ms/step - loss: 2.4930 - val_loss: 3.0162\n",
      "\n",
      "Epoch 00433: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0433.h5\n",
      "Epoch 434/1000\n",
      "150/150 [==============================] - 79s 524ms/step - loss: 2.5120 - val_loss: 3.2074\n",
      "\n",
      "Epoch 00434: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0434.h5\n",
      "Epoch 435/1000\n",
      "150/150 [==============================] - 67s 445ms/step - loss: 2.5075 - val_loss: 3.0354\n",
      "\n",
      "Epoch 00435: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0435.h5\n",
      "Epoch 436/1000\n",
      "150/150 [==============================] - 78s 521ms/step - loss: 2.4990 - val_loss: 3.5255\n",
      "\n",
      "Epoch 00436: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0436.h5\n",
      "Epoch 437/1000\n",
      "150/150 [==============================] - 78s 520ms/step - loss: 2.5199 - val_loss: 3.3504\n",
      "\n",
      "Epoch 00437: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0437.h5\n",
      "Epoch 438/1000\n",
      "150/150 [==============================] - 69s 460ms/step - loss: 2.5009 - val_loss: 2.9271\n",
      "\n",
      "Epoch 00438: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0438.h5\n",
      "Epoch 439/1000\n",
      "150/150 [==============================] - 70s 468ms/step - loss: 2.4846 - val_loss: 3.1599\n",
      "\n",
      "Epoch 00439: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0439.h5\n",
      "Epoch 440/1000\n",
      "150/150 [==============================] - 78s 517ms/step - loss: 2.5146 - val_loss: 3.2868\n",
      "\n",
      "Epoch 00440: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0440.h5\n",
      "Epoch 441/1000\n",
      "150/150 [==============================] - 76s 507ms/step - loss: 2.4997 - val_loss: 3.6830\n",
      "\n",
      "Epoch 00441: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0441.h5\n",
      "Epoch 442/1000\n",
      "150/150 [==============================] - 68s 452ms/step - loss: 2.5142 - val_loss: 3.2416\n",
      "\n",
      "Epoch 00442: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0442.h5\n",
      "Epoch 443/1000\n",
      "150/150 [==============================] - 67s 449ms/step - loss: 2.5070 - val_loss: 3.3315\n",
      "\n",
      "Epoch 00443: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0443.h5\n",
      "Epoch 444/1000\n",
      "150/150 [==============================] - 67s 444ms/step - loss: 2.4934 - val_loss: 3.4189\n",
      "\n",
      "Epoch 00444: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0444.h5\n",
      "Epoch 445/1000\n",
      "150/150 [==============================] - 79s 526ms/step - loss: 2.5160 - val_loss: 3.2383\n",
      "\n",
      "Epoch 00445: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0445.h5\n",
      "Epoch 446/1000\n",
      "150/150 [==============================] - 66s 441ms/step - loss: 2.5040 - val_loss: 3.1739\n",
      "\n",
      "Epoch 00446: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0446.h5\n",
      "Epoch 447/1000\n",
      "150/150 [==============================] - 66s 439ms/step - loss: 2.4857 - val_loss: 3.0919\n",
      "\n",
      "Epoch 00447: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0447.h5\n",
      "Epoch 448/1000\n",
      "150/150 [==============================] - 78s 517ms/step - loss: 2.4902 - val_loss: 3.4605\n",
      "\n",
      "Epoch 00448: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0448.h5\n",
      "Epoch 449/1000\n",
      "150/150 [==============================] - 79s 526ms/step - loss: 2.5054 - val_loss: 3.1493\n",
      "\n",
      "Epoch 00449: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0449.h5\n",
      "Epoch 450/1000\n",
      "150/150 [==============================] - 67s 443ms/step - loss: 2.4901 - val_loss: 3.4352\n",
      "\n",
      "Epoch 00450: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0450.h5\n",
      "Epoch 451/1000\n",
      "150/150 [==============================] - 69s 457ms/step - loss: 2.4894 - val_loss: 3.3369\n",
      "\n",
      "Epoch 00451: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0451.h5\n",
      "Epoch 452/1000\n",
      "150/150 [==============================] - 68s 452ms/step - loss: 2.5054 - val_loss: 3.3231\n",
      "\n",
      "Epoch 00452: saving model to /home/jupyter/GCP_Test/models/pantograph20200429T1039/mask_rcnn_pantograph_0452.h5\n",
      "Epoch 453/1000\n",
      " 13/150 [=>............................] - ETA: 1:09 - loss: 2.4391"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-2:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 349, in put\n",
      "    obj = ForkingPickler.dumps(obj)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/reduction.py\", line 50, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-544836c66122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             layers=\"heads\")\n\u001b[0m",
      "\u001b[0;32m~/GCP_Test/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers)\u001b[0m\n\u001b[1;32m   3082\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3084\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3085\u001b[0m         )\n\u001b[1;32m   3086\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    201\u001b[0m                                      \u001b[0;34m'or `(x, y)`. Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                                      str(generator_output))\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                     \u001b[0;31m# Handle data tensors support when no input given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;31m# step-size = 1 for data tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(train_dataset_keypoints, val_dataset_keypoints, \n",
    "            learning_rate=config.LEARNING_RATE, #\n",
    "            epochs=1000, \n",
    "            layers=\"heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes_test_1.h5\")\n",
    "model.keras_model.save_weights(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
